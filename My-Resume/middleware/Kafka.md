# Kafka 如何保证消息不丢失？
这个就要涉及到Kafka的三者关系：生产者、消费者、Broker，以及Kafka的消息存储机制。

1. Producer默认是异步发送消息的，如果要保证消息不丢失: 
   1. 把异步改为同步发送，会影响性能，因为需要等待Broker的响应。
   2. 在异步中增加回调机制，如果发送失败，允许重试。

# Kafka 怎么避免重复消费？
Kafka中记录消费主要是通过offset来记录的。

1. 也就是如果offset没有提交，kafka就不不会认为这条消息被消费了。（比如宕机和消费者业务代码异常）
2. 还有另一种情况Partition Balance机制触发，发生Rebalance，从而导致Offset提交失败。（比如多个分区交给多个消费者处理，单位时间内无法消费完，就会触发Rebalance）

解决方案：
1. 控制拉取消费数量
2. 延长处理最大时间
3. 优化代码
4. 异步处理业务提前提交offset，但是要通过中间件缓存，可以重新消费。
5. 通过幂等性来解决，比如分布式锁、数据库唯一ID等