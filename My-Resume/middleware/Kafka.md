# Kafka 如何保证消息不丢失？
这个就要涉及到Kafka的三者关系：生产者、消费者、Broker，以及Kafka的消息存储机制。

1. Producer默认是异步发送消息的，如果要保证消息不丢失: 
   1. 把异步改为同步发送，会影响性能，因为需要等待Broker的响应。
   2. 在异步中增加回调机制，如果发送失败，允许重试。

# Kafka 怎么避免重复消费？
Kafka中记录消费主要是通过offset来记录的。

可能情况：
1. 也就是如果offset没有提交，kafka就不不会认为这条消息被消费了。（比如宕机和消费者业务代码异常）
2. 还有另一种情况Partition Balance机制触发，发生Rebalance，从而导致Offset提交失败。（比如多个分区交给多个消费者处理，单位时间内无法消费完，就会触发Rebalance）

解决方案：
1. 控制拉取消费数量
2. 延长处理最大时间
3. 优化代码
4. 异步处理业务提前提交offset，但是要通过中间件缓存，可以重新消费。
5. 通过幂等性来解决，比如分布式锁、数据库唯一ID等

# Kafka 如何保证消息消费的顺序性？
产生乱序的原因：
比如一个Topic下，有多个分区。而生产者产生的消息，被（轮训、随机、hash key的策略）分配给不同的分区。导致消费消息的顺序乱了。

解决方案：
1. 一个Topic下只有一个分区，这样就不会乱序了。但是这样就失去了Kafka的并行处理能力。
2. 自定义一个消费算法，将指定的key发到同一个partition，指定的消费者消费指定的partition。

# kafka怎么保证生产有且仅有一次？
通过幂等性来解决，
比如分布式锁、数据库唯一ID、启用幂等性机制

